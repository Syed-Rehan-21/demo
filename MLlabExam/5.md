A. Consider a sales.csv file with the following data:
| salesman name | region1  | region2  | region3 |
| --------      | -------- | -------- | --------|
| Dinesh        | 7800     | 6500     | 4590    | 
| Mahesh        | 8900     | 2500     |         |
| Ramesh        |          | 3200     | 5800    | 
| Suresh        | 5600     | 6790     | 2300    |

The data represents salesman name and sales in three regions: region1, region2 and region3. Load sles.csv into a data frame called DataFrame3. Give appropriate column names to the columns in DataFrame3. Display the contents of DataFrame3. find the salesmen whose sales are greater than 7000 in region1 but less than 3000 in region2.
```python
import pandas as pd

# Load the sales.csv file into DataFrame3
DataFrame3 = pd.read_csv('sales.csv')

# Assign appropriate column names to DataFrame3
DataFrame3.columns = ['salesman name', 'region1', 'region2', 'region3']

# Display the contents of DataFrame3
print(DataFrame3)

# Find the salesmen whose sales are greater than 7000 in region1 but less than 3000 in region2
filtered_salesmen = DataFrame3[(DataFrame3['region1'] > 7000) & (DataFrame3['region2'] < 3000)]
print("Salesmen with sales > 7000 in region1 and < 3000 in region2:")
print(filtered_salesmen['salesman name'])
```

B. Implement the K-NN algorithm on IRIS and Diabetes datasets. Write down your observations for n_neighbors=3, 4, 5. Finally, set the n_neighbors to the square root of the number of elements in the dataset automatically and note down the observations.
```python
import pandas as pd
from sklearn.datasets import load_iris, load_diabetes
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error
import math

# IRIS dataset
iris_data = load_iris()
X_iris = iris_data.data
y_iris = iris_data.target

# Diabetes dataset
diabetes_data = load_diabetes()
X_diabetes = diabetes_data.data
y_diabetes = diabetes_data.target

# Function to perform K-NN classification
def knn_classification(X, y, n_neighbors):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    knn = KNeighborsClassifier(n_neighbors=n_neighbors)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    return accuracy

# Function to perform K-NN regression
def knn_regression(X, y, n_neighbors):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    knn = KNeighborsRegressor(n_neighbors=n_neighbors)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    return mse

# Observations for IRIS dataset
print("Observations for IRIS dataset:")
for n in [3, 4, 5]:
    accuracy = knn_classification(X_iris, y_iris, n)
    print(f"n_neighbors={n}: Accuracy={accuracy:.4f}")

n_neighbors_auto = math.isqrt(len(X_iris))
accuracy_auto = knn_classification(X_iris, y_iris, n_neighbors_auto)
print(f"n_neighbors=sqrt({len(X_iris)}): Accuracy={accuracy_auto:.4f}")

# Observations for Diabetes dataset
print("\nObservations for Diabetes dataset:")
for n in [3, 4, 5]:
    mse = knn_regression(X_diabetes, y_diabetes, n)
    print(f"n_neighbors={n}: Mean Squared Error={mse:.4f}")

n_neighbors_auto = math.isqrt(len(X_diabetes))
mse_auto = knn_regression(X_diabetes, y_diabetes, n_neighbors_auto)
print(f"n_neighbors=sqrt({len(X_diabetes)}): Mean Squared Error={mse_auto:.4f}")
```