{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqJ7kLwyxjWhwb9Q4+3HKu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## A. Create a numpy array called arr7 using the method arange. The starting value of this array is 120 and ending value is 999, with a step size of 30. Use the linspace method to create another array called arr8, where the starting value is 12 and ending value is 99 and which contains 500 evenly spaced elements."],"metadata":{"id":"vrnTEbl6CL6l"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9hM2wCZB9Bw","executionInfo":{"status":"ok","timestamp":1689718051534,"user_tz":-330,"elapsed":5,"user":{"displayName":"Rehan Quadri","userId":"03143236157719335851"}},"outputId":"74dc7456-451a-45a2-c074-c87220671b89"},"outputs":[{"output_type":"stream","name":"stdout","text":["arr7:\n","[120 150 180 210 240 270 300 330 360 390 420 450 480 510 540 570 600 630\n"," 660 690 720 750 780 810 840 870 900 930 960 990]\n","\n","arr8:\n","[12.         12.1743487  12.34869739 12.52304609 12.69739479 12.87174349\n"," 13.04609218 13.22044088 13.39478958 13.56913828 13.74348697 13.91783567\n"," 14.09218437 14.26653307 14.44088176 14.61523046 14.78957916 14.96392786\n"," 15.13827655 15.31262525 15.48697395 15.66132265 15.83567134 16.01002004\n"," 16.18436874 16.35871743 16.53306613 16.70741483 16.88176353 17.05611222\n"," 17.23046092 17.40480962 17.57915832 17.75350701 17.92785571 18.10220441\n"," 18.27655311 18.4509018  18.6252505  18.7995992  18.9739479  19.14829659\n"," 19.32264529 19.49699399 19.67134269 19.84569138 20.02004008 20.19438878\n"," 20.36873747 20.54308617 20.71743487 20.89178357 21.06613226 21.24048096\n"," 21.41482966 21.58917836 21.76352705 21.93787575 22.11222445 22.28657315\n"," 22.46092184 22.63527054 22.80961924 22.98396794 23.15831663 23.33266533\n"," 23.50701403 23.68136273 23.85571142 24.03006012 24.20440882 24.37875752\n"," 24.55310621 24.72745491 24.90180361 25.0761523  25.250501   25.4248497\n"," 25.5991984  25.77354709 25.94789579 26.12224449 26.29659319 26.47094188\n"," 26.64529058 26.81963928 26.99398798 27.16833667 27.34268537 27.51703407\n"," 27.69138277 27.86573146 28.04008016 28.21442886 28.38877756 28.56312625\n"," 28.73747495 28.91182365 29.08617234 29.26052104 29.43486974 29.60921844\n"," 29.78356713 29.95791583 30.13226453 30.30661323 30.48096192 30.65531062\n"," 30.82965932 31.00400802 31.17835671 31.35270541 31.52705411 31.70140281\n"," 31.8757515  32.0501002  32.2244489  32.3987976  32.57314629 32.74749499\n"," 32.92184369 33.09619238 33.27054108 33.44488978 33.61923848 33.79358717\n"," 33.96793587 34.14228457 34.31663327 34.49098196 34.66533066 34.83967936\n"," 35.01402806 35.18837675 35.36272545 35.53707415 35.71142285 35.88577154\n"," 36.06012024 36.23446894 36.40881764 36.58316633 36.75751503 36.93186373\n"," 37.10621242 37.28056112 37.45490982 37.62925852 37.80360721 37.97795591\n"," 38.15230461 38.32665331 38.501002   38.6753507  38.8496994  39.0240481\n"," 39.19839679 39.37274549 39.54709419 39.72144289 39.89579158 40.07014028\n"," 40.24448898 40.41883768 40.59318637 40.76753507 40.94188377 41.11623246\n"," 41.29058116 41.46492986 41.63927856 41.81362725 41.98797595 42.16232465\n"," 42.33667335 42.51102204 42.68537074 42.85971944 43.03406814 43.20841683\n"," 43.38276553 43.55711423 43.73146293 43.90581162 44.08016032 44.25450902\n"," 44.42885772 44.60320641 44.77755511 44.95190381 45.12625251 45.3006012\n"," 45.4749499  45.6492986  45.82364729 45.99799599 46.17234469 46.34669339\n"," 46.52104208 46.69539078 46.86973948 47.04408818 47.21843687 47.39278557\n"," 47.56713427 47.74148297 47.91583166 48.09018036 48.26452906 48.43887776\n"," 48.61322645 48.78757515 48.96192385 49.13627255 49.31062124 49.48496994\n"," 49.65931864 49.83366733 50.00801603 50.18236473 50.35671343 50.53106212\n"," 50.70541082 50.87975952 51.05410822 51.22845691 51.40280561 51.57715431\n"," 51.75150301 51.9258517  52.1002004  52.2745491  52.4488978  52.62324649\n"," 52.79759519 52.97194389 53.14629259 53.32064128 53.49498998 53.66933868\n"," 53.84368737 54.01803607 54.19238477 54.36673347 54.54108216 54.71543086\n"," 54.88977956 55.06412826 55.23847695 55.41282565 55.58717435 55.76152305\n"," 55.93587174 56.11022044 56.28456914 56.45891784 56.63326653 56.80761523\n"," 56.98196393 57.15631263 57.33066132 57.50501002 57.67935872 57.85370741\n"," 58.02805611 58.20240481 58.37675351 58.5511022  58.7254509  58.8997996\n"," 59.0741483  59.24849699 59.42284569 59.59719439 59.77154309 59.94589178\n"," 60.12024048 60.29458918 60.46893788 60.64328657 60.81763527 60.99198397\n"," 61.16633267 61.34068136 61.51503006 61.68937876 61.86372745 62.03807615\n"," 62.21242485 62.38677355 62.56112224 62.73547094 62.90981964 63.08416834\n"," 63.25851703 63.43286573 63.60721443 63.78156313 63.95591182 64.13026052\n"," 64.30460922 64.47895792 64.65330661 64.82765531 65.00200401 65.17635271\n"," 65.3507014  65.5250501  65.6993988  65.87374749 66.04809619 66.22244489\n"," 66.39679359 66.57114228 66.74549098 66.91983968 67.09418838 67.26853707\n"," 67.44288577 67.61723447 67.79158317 67.96593186 68.14028056 68.31462926\n"," 68.48897796 68.66332665 68.83767535 69.01202405 69.18637275 69.36072144\n"," 69.53507014 69.70941884 69.88376754 70.05811623 70.23246493 70.40681363\n"," 70.58116232 70.75551102 70.92985972 71.10420842 71.27855711 71.45290581\n"," 71.62725451 71.80160321 71.9759519  72.1503006  72.3246493  72.498998\n"," 72.67334669 72.84769539 73.02204409 73.19639279 73.37074148 73.54509018\n"," 73.71943888 73.89378758 74.06813627 74.24248497 74.41683367 74.59118236\n"," 74.76553106 74.93987976 75.11422846 75.28857715 75.46292585 75.63727455\n"," 75.81162325 75.98597194 76.16032064 76.33466934 76.50901804 76.68336673\n"," 76.85771543 77.03206413 77.20641283 77.38076152 77.55511022 77.72945892\n"," 77.90380762 78.07815631 78.25250501 78.42685371 78.6012024  78.7755511\n"," 78.9498998  79.1242485  79.29859719 79.47294589 79.64729459 79.82164329\n"," 79.99599198 80.17034068 80.34468938 80.51903808 80.69338677 80.86773547\n"," 81.04208417 81.21643287 81.39078156 81.56513026 81.73947896 81.91382766\n"," 82.08817635 82.26252505 82.43687375 82.61122244 82.78557114 82.95991984\n"," 83.13426854 83.30861723 83.48296593 83.65731463 83.83166333 84.00601202\n"," 84.18036072 84.35470942 84.52905812 84.70340681 84.87775551 85.05210421\n"," 85.22645291 85.4008016  85.5751503  85.749499   85.9238477  86.09819639\n"," 86.27254509 86.44689379 86.62124248 86.79559118 86.96993988 87.14428858\n"," 87.31863727 87.49298597 87.66733467 87.84168337 88.01603206 88.19038076\n"," 88.36472946 88.53907816 88.71342685 88.88777555 89.06212425 89.23647295\n"," 89.41082164 89.58517034 89.75951904 89.93386774 90.10821643 90.28256513\n"," 90.45691383 90.63126253 90.80561122 90.97995992 91.15430862 91.32865731\n"," 91.50300601 91.67735471 91.85170341 92.0260521  92.2004008  92.3747495\n"," 92.5490982  92.72344689 92.89779559 93.07214429 93.24649299 93.42084168\n"," 93.59519038 93.76953908 93.94388778 94.11823647 94.29258517 94.46693387\n"," 94.64128257 94.81563126 94.98997996 95.16432866 95.33867735 95.51302605\n"," 95.68737475 95.86172345 96.03607214 96.21042084 96.38476954 96.55911824\n"," 96.73346693 96.90781563 97.08216433 97.25651303 97.43086172 97.60521042\n"," 97.77955912 97.95390782 98.12825651 98.30260521 98.47695391 98.65130261\n"," 98.8256513  99.        ]\n"]}],"source":["import numpy as np\n","\n","# Create arr7 using arange\n","arr7 = np.arange(120, 999, 30)\n","\n","# Create arr8 using linspace\n","arr8 = np.linspace(12, 99, 500)\n","\n","# Display arr7 and arr8\n","print(\"arr7:\")\n","print(arr7)\n","print(\"\\narr8:\")\n","print(arr8)\n"]},{"cell_type":"markdown","source":["## B. Implement an ANN on the Diabetes dataset with 3 hidden layers, each with 5 neurons."],"metadata":{"id":"IVucISzCDBPp"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Load the Diabetes dataset\n","diabetes_data = pd.read_csv('diabetes.csv')\n","\n","# Split the dataset into features (X) and target variable (y)\n","X = diabetes_data.drop('Outcome', axis=1)\n","y = diabetes_data['Outcome']\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Create an MLPClassifier with 3 hidden layers, each with 5 neurons\n","mlp = MLPClassifier(hidden_layer_sizes=(5, 5, 5), max_iter=1000, random_state=42)\n","\n","# Train the model\n","mlp.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = mlp.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"syx-9PV7CwW5","executionInfo":{"status":"ok","timestamp":1689718162962,"user_tz":-330,"elapsed":5903,"user":{"displayName":"Rehan Quadri","userId":"03143236157719335851"}},"outputId":"833a1a48-66fe-4c00-fef6-ad2fd5c44d11"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.7597402597402597\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"7OvuRQRbDOpI"},"execution_count":null,"outputs":[]}]}